{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeToMaxDim:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # Get current size\n",
    "        w, h = img.size\n",
    "        if w > h:\n",
    "            new_w = self.max_size\n",
    "            new_h = int(h * (self.max_size / w))\n",
    "        else:\n",
    "            new_h = self.max_size\n",
    "            new_w = int(w * (self.max_size / h))\n",
    "        return img.resize((new_w, new_h), Image.LANCZOS)\n",
    "    \n",
    "class PadToSquare:\n",
    "    def __init__(self, size, fill=0):\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        pad_w = (self.size - w) // 2\n",
    "        pad_h = (self.size - h) // 2\n",
    "        padding = (pad_w, pad_h, self.size - w - pad_w, self.size - h - pad_h)\n",
    "        return transforms.functional.pad(img, padding, fill=self.fill)\n",
    "\n",
    "\n",
    "def plot_image_with_age(model, image_path, csv_data = None, classification = False, image_size = 448):\n",
    "    # Define transformation\n",
    "\n",
    "    \n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Resize(448),\n",
    "    #     #transforms.CenterCrop(600),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # ])\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            ResizeToMaxDim(image_size),\n",
    "            PadToSquare(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    if isinstance(image_path, str):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    else:\n",
    "        image = Image.fromarray(image_path)\n",
    "\n",
    "\n",
    "    input_image_before_cuda = transform(image)\n",
    "    # plt.imshow(input_image_before_cuda.permute(1, 2, 0))\n",
    "    # plt.show()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    input_image = input_image_before_cuda.unsqueeze(0).to(device)\n",
    "\n",
    "    # Get the true age from the CSVnot so clean writtenm since lag_benchmark_cropped is not the best way to make the comparison slower ways I have seen, but couldn come up with similar fast\n",
    "    if csv_data is not None:\n",
    "        true_age = csv_data[csv_data['img_name'] == os.path.join(\"lag_benchmark_cropped\",os.path.basename(image_path))]['age'].values[0]\n",
    "    else:\n",
    "        true_age = -1\n",
    "\n",
    "    # Make prediction\n",
    "    # plt.imshow(input_image_before_cuda.numpy().transpose(1, 2, 0))\n",
    "    # plt.show()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "        if not classification:\n",
    "            predicted_age = output.item()\n",
    "        else:\n",
    "            predicted_age = output\n",
    "       \n",
    "    # Plot the image with the predicted and true age\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    if classification:\n",
    "        predicted_age_group = nn.Softmax(dim=1)(output)\n",
    "        # predicted_age_group = np.argmax(output.cpu().numpy())\n",
    "        # age_group_mapping = {\n",
    "        #     0: '0-2',\n",
    "        #     1: '3-13',\n",
    "        #     2: '18-99',\n",
    "        # }\n",
    "        # predicted_age_group = age_group_mapping.get(predicted_age_group, 'Unknown')\n",
    "        plt.title(f'Estimated Age: {predicted_age_group}\\nTrue Age: {true_age}')\n",
    "\n",
    "    else:\n",
    "        plt.title(f'Estimated Age: {predicted_age:.2f}\\nTrue Age: {true_age}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Regression whole Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "\n",
    "model_weights_path = '/usr/users/vhassle/psych_track/AgeSelf/models/age_classification_model_25.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "model_age = models.resnet50(pretrained=False)\n",
    "num_ftrs = model_age.fc.in_features\n",
    "model_age.fc = nn.Linear(num_ftrs, 1)\n",
    "model_age.load_state_dict(torch.load(model_weights_path))\n",
    "model = model_age.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load true ages from CSV\n",
    "data = pd.read_csv('/usr/users/vhassle/datasets/lagenda/cropped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#image_paths = glob.glob(\"/usr/users/vhassle/datasets/lagenda/lag_benchmark_cropped/*\")\n",
    "data_subset = data[data['age'] != 100]\n",
    "image_paths = [os.path.join('/usr/users/vhassle/datasets/lagenda', image_name) for image_name in data_subset['img_name']]\n",
    "\n",
    "print(len(image_paths))\n",
    "for image_path in image_paths[2134:2135]:\n",
    "    plot_image_with_age(model_age, image_path, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age classification whole Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "# model_weights_path = '/usr/users/vhassle/datasets/lagenda/age_classification_model.pth'\n",
    "model_weights_path = '/usr/users/vhassle/psych_track/AgeSelf/models/age_classification_model_15_focal_pad.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "model_age = models.resnet50(pretrained=False)\n",
    "num_ftrs = model_age.fc.in_features\n",
    "model_age.fc = nn.Linear(num_ftrs, 3)\n",
    "model_age.load_state_dict(torch.load(model_weights_path))\n",
    "model = model_age.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load true ages from CSV\n",
    "data_class = pd.read_csv('/usr/users/vhassle/datasets/lagenda/cropped_data_age_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = data[data['age'] != 100]\n",
    "image_paths = [os.path.join('/usr/users/vhassle/datasets/lagenda', image_name) for image_name in data_subset['img_name']]\n",
    "\n",
    "print(len(image_paths))\n",
    "for image_path in image_paths[0:100:100]:\n",
    "    plot_image_with_age(model_age, image_path, data, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#image_paths = glob.glob(\"/usr/users/vhassle/psych_track/Gender-and-Age-Detection_Face/*.jpg\")\n",
    "image_paths = glob.glob(\"/usr/users/vhassle/datasets/Wortschatzinsel/cropped_images/*.jpg\")\n",
    "for image_path in image_paths:\n",
    "    plot_image_with_age(model_age, image_path, None, classification=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FÃ¼r die Gesichter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model weights\n",
    "# model_weights_path = '/usr/users/vhassle/datasets/lagenda/age_classification_model.pth'\n",
    "model_weights_path = '/usr/users/vhassle/psych_track/AgeSelf/models/faces/age_classification_model_25_focal.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "model_age = models.resnet50(pretrained=False)\n",
    "num_ftrs = model_age.fc.in_features\n",
    "model_age.fc = nn.Linear(num_ftrs, 3)\n",
    "model_age.load_state_dict(torch.load(model_weights_path))\n",
    "model_age = model_age.to(device)\n",
    "model_age.eval()\n",
    "# Load true ages from CSV\n",
    "data_class = pd.read_csv('/usr/users/vhassle/datasets/lagenda/cropped_data_age_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#image_paths = glob.glob(\"/usr/users/vhassle/psych_track/Gender-and-Age-Detection_Face/*.jpg\")\n",
    "#image_paths = glob.glob(\"/usr/users/vhassle/datasets/Wortschatzinsel/cropped_images/*.jpg\")\n",
    "image_paths = glob.glob(\"/usr/users/vhassle/datasets/example_images/children/*\")\n",
    "for image_path in image_paths:\n",
    "    plot_image_with_age(model_age, image_path, None, classification=True, image_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining face detection with age classification in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from annotate_videos_functions import process_video\n",
    "from pytorch_retinaface.detect import process_image, load_Retinanet \n",
    "\n",
    "class ResizeToMaxDim:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # Get current size\n",
    "        w, h = img.size\n",
    "        if w > h:\n",
    "            new_w = self.max_size\n",
    "            new_h = int(h * (self.max_size / w))\n",
    "        else:\n",
    "            new_h = self.max_size\n",
    "            new_w = int(w * (self.max_size / h))\n",
    "        return img.resize((new_w, new_h), Image.LANCZOS)\n",
    "    \n",
    "class PadToSquare:\n",
    "    def __init__(self, size, fill=0):\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        pad_w = (self.size - w) // 2\n",
    "        pad_h = (self.size - h) // 2\n",
    "        padding = (pad_w, pad_h, self.size - w - pad_w, self.size - h - pad_h)\n",
    "        return transforms.functional.pad(img, padding, fill=self.fill)\n",
    "\n",
    "def plot_image_with_estimated_ages(image, model_age, model_face_detection ,index_frame = 0, classification=True, image_size=448):\n",
    "    \"\"\"\n",
    "    Plots an image with estimated ages annotated on detected faces.\n",
    "\n",
    "    Parameters:\n",
    "    image (Union[str, np.ndarray]): Path to the image or a NumPy array representing the image.\n",
    "    model: The model used for age estimation.\n",
    "    classification (bool): If True, classify the age group. If False, predict the exact age.\n",
    "    image_size (int): The size to which the image should be resized.\n",
    "    \"\"\"\n",
    "    # Define transformation\n",
    "    transform = transforms.Compose([\n",
    "        ResizeToMaxDim(image_size),\n",
    "        PadToSquare(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load the image\n",
    "    if isinstance(image, str):\n",
    "        frame = cv2.imread(image)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        frame_rgb = image\n",
    "        frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "    else:\n",
    "        raise ValueError(\"image must be a file path or a numpy array\")\n",
    "\n",
    "    # Detect faces\n",
    "    faces = process_image(model_face_detection, frame_rgb)\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Prepare for prediction\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    annotations = []\n",
    "\n",
    "    for face_key in faces.keys():\n",
    "        face_area = faces[face_key]\n",
    "        x1, y1, x2, y2 = face_area\n",
    "        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(width, x2), min(height, y2)\n",
    "\n",
    "        # Extract the face\n",
    "        face = frame_rgb[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert the face to PIL image and apply transformation\n",
    "        face_pil = Image.fromarray(face)\n",
    "        input_image_before_cuda = transform(face_pil)\n",
    "        input_image = input_image_before_cuda.unsqueeze(0).to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            output = model_age(input_image)\n",
    "            if not classification:\n",
    "                predicted_age = output.item()\n",
    "                predicted_age_text = f'Age: {predicted_age:.2f}'\n",
    "            else:\n",
    "                predicted_age_group = nn.Softmax(dim=1)(output)\n",
    "                age_group = predicted_age_group.argmax(dim=1).item()\n",
    "                predicted_age_text = f'{age_group}'\n",
    "\n",
    "        # Annotate the image using OpenCV\n",
    "        cv2.rectangle(frame_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame_rgb, predicted_age_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # Prepare annotation for MOT format\n",
    "        annotation = [index_frame, face_key, x1, y1, x2 - x1, y2 - y1, 1, -1, -1, -1, age_group]\n",
    "        annotations.append(annotation)\n",
    "\n",
    "    return frame_rgb, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frame = Image.open(\"/usr/users/vhassle/datasets/example_images/children/1000_F_140125186_ktTYm8WJ8EDK7Fc82g9A9OU3OrTa5cyg.jpg\")\n",
    "frame = np.asarray(frame)\n",
    "model_face_detection = load_Retinanet(\"/usr/users/vhassle/psych_track/Pytorch_Retinaface/Resnet50_Final.pth\")\n",
    "\n",
    "model_weights_path = '/usr/users/vhassle/psych_track/AgeSelf/models/faces/age_classification_model_final_focal.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "model_age = models.resnet50(pretrained=False)\n",
    "num_ftrs = model_age.fc.in_features\n",
    "model_age.fc = nn.Linear(num_ftrs, 3)\n",
    "model_age.load_state_dict(torch.load(model_weights_path))\n",
    "model_age = model_age.to(device)\n",
    "model_age.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_paths = glob.glob(\"/usr/users/vhassle/datasets/example_images/children/*\")\n",
    "for image_path in image_paths:\n",
    "    frame, annotations = plot_image_with_estimated_ages(image_path, model_age, model_face_detection ,index_frame = 0, classification=True, image_size=150)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
